---
title: "Stops of people in schools by stop reason"
author: "Alicia Vo"
date: "2025-06-04"
output: html_document
---

# Get data
```{r}
library(RPostgreSQL)
library(dplyr)
library(stringr)
library(tidytext)

# Connect to postgres
source("W:\\RDA Team\\R\\credentials_source.R")
con_rda <- connect_to_db("rda_shared_data")
con_ctc <- connect_to_db("cancel_the_contract")

# Get LASD stop-level data for Antelope Valley high schools
lasd_stops_incident_raw <- dbGetQuery(con_rda, "SELECT contact_id, school_name, full_street, civilians_contacted, call_for_service FROM crime_and_justice.lasd_stops_incident_2018_2023
WHERE school_name
IN (
'Antelope Valley High',
'Antelope Valley Union High',
'Eastside High',
'Highland High',
'William J. (Pete) Knight High',
'Lancaster High',
'Littlerock High',
'Palmdale High',
'Quartz Hill High',
'R. Rex Parris High',
'Desert Winds Continuation High',
'Phoenix High Community Day',
'Phoenix Continuation')
ORDER BY school_name") 

# We only want to analyze officer-initiated stops
unique(lasd_stops_incident_raw$call_for_service) # "false" "true"  "No"    "Yes"  
lasd_stops_incident <- lasd_stops_incident_raw %>% 
  filter(call_for_service=='false' | call_for_service=="No")
unique(lasd_stops_incident$call_for_service) # "false" "No"   

# Get LASD person-level data
lasd_stops_person_raw <- dbGetQuery(con_rda, "SELECT contact_id, person_id, full_address, reason_for_contact, reason_for_contact_narrative FROM crime_and_justice.lasd_stops_person_2018_2023")

# Join person-level data with stop-level data, such that each row represents one person. A RIGHT JOIN returns all records from the right table, along with the matching records from the left table
person <- lasd_stops_person_raw %>% right_join(lasd_stops_incident, by="contact_id")

unique(person$reason_for_contact)
unique(person$reason_for_contact_narrative)
```

# Examine word frequency. 
```{r}
# Standardize for case, punctuation, etc.
person_clean <- person %>%
  mutate(reason_clean = str_to_lower(reason_for_contact_narrative),
         reason_clean = str_replace_all(reason_clean, "[^a-z\\s]", ""), # remove punctuation
         reason_clean = str_squish(reason_clean)) # remove extra spaces

# Basic word count
word_freq <- person_clean %>%
  # Tokenize the 'reason_clean' text column into individual words. 
  # Each word gets its own row.
  unnest_tokens(word, reason_clean) %>%
  count(word, sort = TRUE)
```

